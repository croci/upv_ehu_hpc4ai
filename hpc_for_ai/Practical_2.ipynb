{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1053038-5b96-495a-8744-7a42064f55bb",
   "metadata": {},
   "source": [
    "High-performance and parallel computing for AI - Practical 2: JIT & Wrapping\n",
    "============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6baf3cbf-7406-4a98-8e45-ab80587cce7d",
   "metadata": {},
   "source": [
    "IMPORTANT\n",
    "=========\n",
    "\n",
    "For these practicals we will be using a different `conda environment`. When opening a notebook or a terminal make sure you are using the **CuPy Kernel**!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a88eed-fc67-49d7-839e-1a0e6e1514ae",
   "metadata": {},
   "source": [
    "Tutorial 1 - Numba and Just-in-time compiling\n",
    "---------------------------------------------\n",
    "\n",
    "For this part we will be using [numba](https://numba.pydata.org/). Numba is an open source just-in-time compiler that translates a subset of Python and NumPy code into fast machine code. In this question we investigate the use of JIT. Note: there may be some overlaps with other parts of the course, but we will be using numba later on in the GPU part.\n",
    "\n",
    "**Warning:** For reasons that will be obvious soon before running the scripts in this question you should restart the Jupyter kernel (click on the circular arrow or the fast-forward sign above).\n",
    "\n",
    "The easiest way to start working with numba is to import the numba JIT decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b7cd07d-3edb-4cdb-b561-f44be245b719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f1863a-b7c1-4ce0-8aee-7b8a4e48216c",
   "metadata": {},
   "source": [
    "Consider the script "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de5b94d-17c7-4cdc-9045-f1e9fcebab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002525806427001953\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "N = 10000\n",
    "a = np.random.randn(N)\n",
    "b = np.random.randn(N)\n",
    "\n",
    "def f(a,b):\n",
    "    out = a.copy()\n",
    "    for i in range(N):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "    return out\n",
    "\n",
    "tic = time()\n",
    "c = f(a,b)\n",
    "toc = time()-tic\n",
    "print(toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f35dce-7901-4742-81f4-d2cc5b65a12b",
   "metadata": {},
   "source": [
    "The above is not the best way of working in Python: Python for loops are very slow. What we should do is use vectorization (see later).\n",
    "However, another option is to use numba to compile the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31db5fd5-b1c3-4f10-a007-34683992d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With compilation: 0.37271833419799805\n",
      "Without compilation: 6.103515625e-05\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def fjit(a,b):\n",
    "    out = a.copy()\n",
    "    for i in range(N):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "    return out\n",
    "\n",
    "# The first time the function is called, numba will use JIT to compile the function.\n",
    "tic = time()\n",
    "c = fjit(a,b)\n",
    "toc = time()-tic\n",
    "print(\"With compilation:\", toc)\n",
    "\n",
    "# The second time the function is called no compilation will occur so it will be faster!\n",
    "tic = time()\n",
    "c = fjit(a,b)\n",
    "toc = time()-tic\n",
    "print(\"Without compilation:\", toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aefbf54-4b7f-4a2e-824b-ae82944807ca",
   "metadata": {},
   "source": [
    "The compiled code is now much much faster! However, you can see the big downside of JIT: compilation took a very long time, much longer than the pure Python for loop!\n",
    "\n",
    "To make things worse, a change of variable type will trigger another JIT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "144ea6cf-b2ac-4de5-9f0c-daed22857a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already JIT-ed: 0.00021314620971679688\n",
      "Argh! Re-JIT: 0.11827611923217773\n",
      "Already JIT-ed: 6.246566772460938e-05\n",
      "Already JIT-ed: 9.012222290039062e-05\n"
     ]
    }
   ],
   "source": [
    "# No JIT here, this was compiled before so it's fast\n",
    "tic = time()\n",
    "c = fjit(a,b)\n",
    "toc = time()-tic\n",
    "print(\"Already JIT-ed:\", toc)\n",
    "\n",
    "# If you change variable types: re-JIT\n",
    "aa = a.astype(np.int64)\n",
    "bb = b.astype(np.int64)\n",
    "tic = time()\n",
    "cc = fjit(aa,bb)\n",
    "toc = time()-tic\n",
    "print(\"Argh! Re-JIT:\", toc)\n",
    "\n",
    "# This was JIT-ed before so now we are fine!\n",
    "aa = a.astype(np.int64)\n",
    "bb = b.astype(np.int64)\n",
    "tic = time()\n",
    "cc = fjit(aa,bb)\n",
    "toc = time()-tic\n",
    "print(\"Already JIT-ed:\", toc)\n",
    "\n",
    "# Changing array size won't trigger recompilation though\n",
    "tic = time()\n",
    "cc = fjit(aa[:-1],bb[:-1])\n",
    "toc = time()-tic\n",
    "print(\"Already JIT-ed:\", toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e9975-1915-4bf2-9807-b80b017e5926",
   "metadata": {},
   "source": [
    "You can prescribe input and output types if you want:\n",
    "1- It may make compilation slightly faster.\n",
    "2- It will throw an error if you try using the function with the wrong input/output type\n",
    "\n",
    "To prescribe types you need to provide a *function signature* to the decorator:\n",
    "```python\n",
    "    import numba as nb\n",
    "    @jit(nb.float32(nb.float32, nb.float32))\n",
    "```\n",
    "\n",
    "The above means that the function being JIT-ed takes two single-precision variables as inputs and returns one single precision variable. These are for scalars. If you want to use vectors you will have to use, e.g., `nb.float32[:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a3aea0-c7bd-40a7-ab0f-aeb58ae85130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba as nb\n",
    "\n",
    "@jit(nb.float64[:](nb.float64[:], nb.float64[:])) # This is called the function signature\n",
    "def fjit(a,b):\n",
    "    out = a.copy()\n",
    "    for i in range(N):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "    return out\n",
    "\n",
    "c = fjit(a,b) # no problem\n",
    "\n",
    "## Try uncommenting the lines below for fun\n",
    "#fjit(aa,bb) # aa and bb are arrays of integers so numba will complain\n",
    "#fjit(3.0,2.0) # these are scalars and not arrays o numba will complain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e037f2-5769-450a-967d-f70761345f05",
   "metadata": {},
   "source": [
    "Important! Use `nb.void` for functions that do not return anything, e.g.,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f8b34e-11ae-46c9-82f5-4ef23ddabb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    }
   ],
   "source": [
    "@jit(nb.void(nb.float64))\n",
    "def test(a):\n",
    "    print(a)\n",
    "\n",
    "test(4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf537c-c318-4dd5-ae6e-8b42749f9864",
   "metadata": {},
   "source": [
    "If you use nested functions, please **jit them all**! Note: this is numba-specific. In other libraries (notably Jax) you only need to JIT the outermost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b6ccdc4-5401-4457-a6ca-9b5e95258e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def anincrediblefunction(a):\n",
    "    return fjit(a,a) # fjit was already decorated with jit. This is good practice when using numba.\n",
    "\n",
    "c = anincrediblefunction(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04025a18-856a-46c2-a74b-22eeeaff7329",
   "metadata": {},
   "source": [
    "Note that numba has two compilation modes: a `nopython` mode which will avoid using interpeted Python calls (which are slow) and an `object` mode which allows interpreted Python calls and is compatible with Python objects that cannot be compiled. `object` mode is always very slow: good for debugging, but in general it should be avoided.\n",
    "\n",
    "By default, the `jit` decorator will use `nopython` mode (which is good!). In old versions of numba it didn't and you had to use the `njit` decorator instead. If you want to use `object` mode use instead `jit` with `nopython=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b701b5f1-d6ad-46c8-aebc-04999842d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=False)\n",
    "def fjit(a,b):\n",
    "    out = a.copy()\n",
    "    for i in range(N):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "    return out\n",
    "\n",
    "# Note: I suspect that for such a simple function numba will be fast anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e0ed3b-6151-4e8a-935a-b677c52d47f3",
   "metadata": {},
   "source": [
    "**Warning** Numba does not like a lot of things, including:\n",
    "* **External libraries**. If you try to use anything other than numpy (or a few numba-supported libraries) with numba it won't work.\n",
    "* **Python classes**. Classes won't work inside JIT-ed code *unless* you compile them with the experimental feature `@jitclass`.\n",
    "\n",
    "This makes numba annoying at times. However, it offers a very easy way of compiling Python code and making it much much faster. Additionally, it allows to do the same using GPUs, which is a great feature.\n",
    "\n",
    "**A few curiosities:**\n",
    "* numba uses the LLVM compiler under the hood.\n",
    "* JAX also uses JIT. However it uses the XLA compiler (my take is that LLVM is faster and XLA has a few quirks such as it is slow for loops and does not like a few operations such as editing vector entries, but I am not an expert) and it is designed with automatic differentiation and machine learning applications in mind rather than JIT. Jax is not compatible with numpy (it uses its own numpy library instead, jax.numpy).\n",
    "* The other AI libraries (PyTorch, TensorFlow) also use JIT.\n",
    "* Julia is a programming language that tries to bridge between compiled and interpreted languages. It is as easy as python, but it JITs everything so as to achieve compiled language speeds. However big catch: JIT compiling time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebccda64-036e-44c7-9556-f09926edbe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-04-27 10:05:24,672:jax._src.xla_bridge:966: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using numba\n",
      "\n",
      "With compilation: 0.09668779373168945\n",
      "Without compilation: 7.152557373046875e-05\n",
      "\n",
      "\n",
      "Using JAX\n",
      "\n",
      "With compilation: 0.04004979133605957\n",
      "Without compilation: 0.0004780292510986328\n"
     ]
    }
   ],
   "source": [
    "# Here is a short jax example\n",
    "import jax\n",
    "\n",
    "# This is being unfair to JAX: you could just do a + b and Jax does not like for loops\n",
    "# so you need this convoluted way.\n",
    "@jax.jit\n",
    "def jax_fjit(a, b):\n",
    "    out = jax.numpy.zeros_like(a)\n",
    "    \n",
    "    def body_fun(i, result):\n",
    "        return result.at[i].set(a[i] + b[i])  # Functional update\n",
    "    \n",
    "    return jax.lax.fori_loop(0, N, body_fun, out)\n",
    "\n",
    "@jit\n",
    "def numba_fjit(a,b):\n",
    "    out = a.copy()\n",
    "    for i in range(N):\n",
    "        out[i] = a[i] + b[i]\n",
    "\n",
    "    return out\n",
    "\n",
    "# Numba again\n",
    "print(\"Using numba\\n\")\n",
    "tic = time()\n",
    "c = numba_fjit(a,b)\n",
    "toc = time()-tic\n",
    "print(\"With compilation:\", toc)\n",
    "\n",
    "tic = time()\n",
    "c = numba_fjit(a,b)\n",
    "toc = time()-tic\n",
    "print(\"Without compilation:\", toc)\n",
    "\n",
    "# Using JAX\n",
    "print(\"\\n\\nUsing JAX\\n\")\n",
    "\n",
    "# need to convert to jax.numpy arrays first\n",
    "aa = jax.numpy.array(a)\n",
    "bb = jax.numpy.array(b)\n",
    "\n",
    "tic = time()\n",
    "cc = jax_fjit(aa,bb)\n",
    "toc = time()-tic\n",
    "print(\"With compilation:\", toc)\n",
    "\n",
    "tic = time()\n",
    "cc = jax_fjit(aa,bb)\n",
    "toc = time()-tic\n",
    "print(\"Without compilation:\", toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "090b596e-5678-4bde-b971-29d0b2824109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure numpy: 0.00028896331787109375\n"
     ]
    }
   ],
   "source": [
    "# Just so you know, numpy code IS COMPILED so using pure numpy will already be quite fast:\n",
    "\n",
    "tic = time()\n",
    "c = a+b\n",
    "toc = time()-tic\n",
    "print(\"Pure numpy:\", toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaae1ee-e534-4f44-a256-8d805d97f081",
   "metadata": {},
   "source": [
    "Note that this example is unfair to JAX: you could just do `a + b` as in numpy and it would work and it would be faster, plus for loops are especially slow in JAX.\n",
    "Nevertheless it shows like each alternative has its own pros and cons. numba is designed specifically for JIT-ing so I expect it to be fast in general. For things that you cannot use numpy (or jax.numpy) for, numba is likely to be a great option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8655de-be86-4a4b-a7ea-5d58768f882f",
   "metadata": {},
   "source": [
    "**Conclusions**\n",
    "This short tutorial was just to introduce you to the basic of JIT and to prepare you for the GPU tutorial in which we may be using numba. If you want to read more about numba, please checkout its official [documentation](https://numba.readthedocs.io/en/stable/index.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026cec17-33bf-45a1-8aed-45e68d91f8ca",
   "metadata": {},
   "source": [
    "Problem 1\n",
    "---------\n",
    "\n",
    "Write a Python function that uses for loops to compute $\\lVert \\sin(Ab) \\rVert_2$, where $A$ is a random square matrix of size $N=1024$ and $b$ is a random vector of compatible sizes. Compile it with numba and compute the timings of: 1) The pure Python code. 2) The first time the numba-jitted code is run. 3) The second time the numba-jitted code is run. Check that they match with what we observed in the practical so far.\n",
    "\n",
    "Now, try using numpy.linalg.norm to compute the Euclidean norm and try to compile the code with numba. What happens? Try to understand the error message and note that numba does not give very clear messages when it fails to compile. Now, circumvent the problem by compiling it by passing nopython=False to the jit decorator so that numba uses object mode. Does it work now? Compare the timings of using nopython=False VS your previous code. What do you observe? Think about why using object mode is always a bad idea and why we have been lucky here. \n",
    "\n",
    "\n",
    "Hint: You may have to restart the jupyterhub kernel to make sure JIT compiling happens.\n",
    "Hint: Always write the pure Python code first and check that it runs before jitting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84349914-41f3-43d4-99f1-e0f8fe59d63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure Python: 0.32219743728637695\n",
      "With compilation: 0.2579164505004883\n",
      "Without compilation: 0.0009684562683105469\n",
      "With compilation: 0.22426271438598633\n",
      "Without compilation: 0.0009686946868896484\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit\n",
    "\n",
    "N = 1024\n",
    "A = np.random.randn(N,N)\n",
    "b = np.random.randn(N)\n",
    "\n",
    "def myfun(A,b):\n",
    "    c = np.zeros_like(b)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            c[i] += A[i,j]*b[j]\n",
    "\n",
    "    for i in range(N):\n",
    "        c[i] = np.sin(c[i])**2\n",
    "\n",
    "    out = 0\n",
    "    for i in range(N):\n",
    "        out += c[i]\n",
    "\n",
    "    out = np.sqrt(out)\n",
    "    return out\n",
    "\n",
    "# Can also jit this way\n",
    "jit_myfun = jit(myfun)\n",
    "\n",
    "tic = time()\n",
    "cc = myfun(A,b)\n",
    "toc = time()-tic\n",
    "print(\"Pure Python:\", toc)\n",
    "\n",
    "tic = time()\n",
    "cc = jit_myfun(A,b)\n",
    "toc = time()-tic\n",
    "print(\"With compilation:\", toc)\n",
    "\n",
    "tic = time()\n",
    "cc = jit_myfun(A,b)\n",
    "toc = time()-tic\n",
    "print(\"Without compilation:\", toc)\n",
    "\n",
    "# Note: Using np.linalg.norm throws a compilation error in which it asks you to use object mode.\n",
    "#       This happens since numba does not support numpy.linalg.\n",
    "\n",
    "@jit(nopython=False)\n",
    "def jit_mybadfun(A,b):\n",
    "    c = np.zeros_like(b)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            c[i] += A[i,j]*b[j]\n",
    "\n",
    "    for i in range(N):\n",
    "        c[i] = np.sin(c[i])\n",
    "\n",
    "    out = np.linalg.norm(c)\n",
    "    return out\n",
    "\n",
    "tic = time()\n",
    "cc = jit_mybadfun(A,b)\n",
    "toc = time()-tic\n",
    "print(\"With compilation:\", toc)\n",
    "\n",
    "tic = time()\n",
    "cc = jit_mybadfun(A,b)\n",
    "toc = time()-tic\n",
    "print(\"Without compilation:\", toc)\n",
    "\n",
    "# Using object mode is a bad idea since it will use pure Python to evaluate code it is not able to compile.\n",
    "# However here we are lucky since np.linalg.norm invokes compiled code under the hood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc643c8f-10b0-47ca-98f8-246608ec664b",
   "metadata": {},
   "source": [
    "Tutorial 2 - Quick wrapper example\n",
    "-----------------------------------\n",
    "\n",
    "An alternative to JIT compiling is to write code in a *compiled* language (e.g., C/C++, Fortran, Rust, etc.) and then compiling it and calling it from Python.\n",
    "\n",
    "However, I cannot assume you know anything other than Python so I am only going to show you a small example using CFFI - The Common Foreign Function Interface.\n",
    "\n",
    "Frankly, I do not advise you learn CFFI, there are better packages such as (for C/C++):\n",
    "* [Pybind11](https://github.com/pybind/pybind11).\n",
    "* [Nanobind](https://github.com/wjakob/nanobind).\n",
    "\n",
    "For other languages there are likely other very good options.\n",
    "\n",
    "Nevertheless, CFFI allows me to show you an example without ever leaving Python. Using anything else would require writing C/C++ code, compiling it on the side etc. which is a bit tricky with Jupyter notebooks so here it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280d3838-9212-4e21-9915-2f382cfb1cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.58124424024471\n",
      "With wrapper: 8.058547973632812e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cffi\n",
    "\n",
    "ffi = cffi.FFI()\n",
    "# Tell CFFI to expect the add_arrays function\n",
    "ffi.cdef(\"void add_arrays(const double* a, const double* b, double* out);\")\n",
    "# define source code: a simple function to add 2 arrays. The output array out must be passed as input. It will be modified.\n",
    "C_SOURCE = \"#define N %d\\n\" % N + '''\n",
    "void add_arrays(const double* a, const double* b, double* out) {\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        out[i] = a[i] + b[i];\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "# Compiles the code. This is very similar to JIT, but normally it is done offline and separately and only once.\n",
    "C = ffi.verify(\n",
    "    C_SOURCE,\n",
    "    extra_compile_args=[\"-O3\", \"-ffast-math\"]\n",
    ")\n",
    "\n",
    "# Create input arrays and output buffer\n",
    "a = np.random.randn(N)\n",
    "b = np.random.randn(N)\n",
    "out = np.empty_like(a)\n",
    "\n",
    "# Execute C function with array buffers\n",
    "C.add_arrays(\n",
    "    ffi.cast(\"const double*\", a.ctypes.data),\n",
    "    ffi.cast(\"const double*\", b.ctypes.data),\n",
    "    ffi.cast(\"double*\", out.ctypes.data)\n",
    ")\n",
    "\n",
    "print(np.linalg.norm(out))\n",
    "\n",
    "out = np.empty_like(a)\n",
    "tic = time()\n",
    "C.add_arrays(\n",
    "    ffi.cast(\"const double*\", a.ctypes.data),\n",
    "    ffi.cast(\"const double*\", b.ctypes.data),\n",
    "    ffi.cast(\"double*\", out.ctypes.data)\n",
    ")\n",
    "toc = time()-tic\n",
    "print(\"With wrapper:\", toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f581b2-5c7d-4208-af2c-ffa62ecaa390",
   "metadata": {},
   "source": [
    "The above is fast, but not as fast as numba.I never used CFFI, but in my experience the other wrappers are faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8b2851-0e1b-464c-bd20-179d212e5a17",
   "metadata": {},
   "source": [
    "Problem 2 (bonus)\n",
    "-----------------\n",
    "\n",
    "This is a bonus problem. Only work on it if you are done for the day. You can go back on it on a later day if you have time.\n",
    "\n",
    "Read the numba [jitclass documentation](https://numba.readthedocs.io/en/stable/user/jitclass.html). Create a new \"CrazyNumberArray\" class which stores a numpy array and overloads its `__mul__` and `__add__` operations so that the result of each operation is perturbed by an independent uniform random variable in $[-10^{-6}, 10^{-6}]$. Use the `numba.jitclass` decorator to JIT-compile the class. Check that it becomes faster.\n",
    "\n",
    "Hint: you can generate uniform random variables by using `numpy.random.rand`. However, these are standard uniforms and they lie in $[0,1]$. Think about how you can map them to the desired interval.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy Kernel",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
