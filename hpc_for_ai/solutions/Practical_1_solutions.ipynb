{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68281218-b119-4671-a586-5d8f3019bf21",
   "metadata": {},
   "source": [
    "High-performance and parallel computing for AI - Practical 1: HPC Architecture\n",
    "==============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf1c7e8-2389-412c-9644-bab3729b6c16",
   "metadata": {},
   "source": [
    "IMPORTANT\n",
    "=========\n",
    "\n",
    "For these practicals we will be using a different `conda environment`. When opening a notebook or a terminal make sure you are using the **CuPy Kernel**!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae4df79-3978-4919-8018-d5a1559e7749",
   "metadata": {},
   "source": [
    "Question 1\n",
    "----------\n",
    "\n",
    "This question is to help you understand the architecture of a computing server.\n",
    "\n",
    "In Jupyter, open a new window and open a terminal. On the terminal, type\n",
    "\n",
    "```bash\n",
    "lscpu\n",
    "```\n",
    "\n",
    "This outputs a plethora of information about goliat's CPU. Can you answer the following questions?\n",
    "\n",
    "1- Who is the CPU manufacturer? Which year was this CPU commercialized (you will have to google the CPU model)?\n",
    "\n",
    "2- How many cores does the CPU have? Be careful, google what hyperthreading is (goliat has it enabled).\n",
    "\n",
    "3- What is the largest square matrix of doubles (64 bits) that you can fit in the L1i cache?\n",
    "\n",
    "4- Assuming a similar architecture as the one we saw in the lectures in which the L3 cache is shared. What is the largest double (64-bit) square matrix size that you can fit on a socket without spilling over to the RAM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ea65f3-9fc0-47d2-955f-531edd92291a",
   "metadata": {},
   "source": [
    "Solution to question 1\n",
    "----------------------\n",
    "\n",
    "1- AMD. Product launched in 2021.\n",
    "\n",
    "2- 128, but it is using hyperthreading so it looks as if you had 256.\n",
    "\n",
    "3- sqrt(4MB/(64 bits)/128 (number of L1i caches)) = 62.\n",
    "\n",
    "4- 584 MB of total caches. Divide by 4 since there are 2 sockets and 2 core dies per socket gives 146 MB. sqrt(146MB/(64 bits))\\approx 4289. Can store a matrix of size up to $4289$ without spilling over to the RAM. In practice some additional memory will always be occupied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c86fce-5a7e-446a-91f2-0d8f7e5c127b",
   "metadata": {},
   "source": [
    "Question 2\n",
    "----------\n",
    "\n",
    "This question is to teach you how to compute whether a computation is compute or memory bound.\n",
    "\n",
    "Assume you are using a CPU with a peak computational performance of 500 GFLOPs/s and a memory bandwidth of 50 GB/s (this could roughly be a laptop's CPU). Let $n=1024$ and take $A,B\\in\\mathbb{R}^{n\\times n}$, $v\\in\\mathbb{R}^n$. Assume they are stored in single precision (32 bits/number). Are the following computations memory- or compute-bound?\n",
    "\n",
    "1- The matrix-vector product $Av$.\n",
    "\n",
    "2- The matrix-matrix product $AB$.\n",
    "\n",
    "Draw a roofline plot. Where would these computations be on the plot? What would happen if the matrices and vectors were booleans (e.g., only 1 bit)?\n",
    "\n",
    "\n",
    "Hints: First, compute the FLOPs of each operation, then the memory occupied by each variable. Second, compute the arithmetic intensity (FLOPs/memory required). Third, draw the roofline plot. Lastly, add the arithmetic intensities of the operations (include them by drawing a vertical line: the problem does not give you the GFLOPS performance of these operations, you would need to test it in practice). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9561d1-5f93-430c-b017-947ded58a558",
   "metadata": {},
   "source": [
    "Solution to Question 2\n",
    "----------------------\n",
    "\n",
    "**Cost.**\n",
    "* Matvec cost $= 2n^2 \\approx 2$ MFLOPs.\n",
    "* Matmat cost $= 2n^3 \\approx 2$ GFLOPs. \n",
    "\n",
    "**Memory occupied.**\n",
    "* Matvec $= n^2 + n$ single-precision numbers $ \\approx 4.2$MB.\n",
    "* Matmat $= 2n^2$ single-precision numbers $ \\approx 8.4$ MB.\n",
    "\n",
    "**Arithmetic intensity.**\n",
    "* Matvecs $2$ MFLOPs $ /$ $4.2$MB $ \\approx 0.5$ FLOPs/Byte.\n",
    "* Matmats $2$ GFLOPs $ /$ $8.4$MB $ \\approx 240$ FLOPs/Byte\n",
    "\n",
    "In the roofline plot, the threshold between memory and compute bound occurs in the corner of the roofline (the black line in the lectures). This is when\n",
    "\n",
    "$$ \\text{bandwidth} \\times \\text{arithmetic intensity} = \\text{peak performance} $$\n",
    "\n",
    "which happens at the arithmetic intensity given by\n",
    "\n",
    "$$ \\text{threshold intensity} = \\frac{\\text{peak performance}}{\\text{bandwidth}} = \\frac{500 \\text{GFLOPs/s}}{50 \\text{GB/s}} = 10 \\text{FLOPs/Byte}. $$\n",
    "\n",
    "**Result**\n",
    "* Since $0.5 < 10$, matvecs are memory-bound.\n",
    "* Since $240 > 10$, matmats are compute-bound.\n",
    "* In the case in which numbers are booleans you would be using $1/32$nd of the bits so the arithmetic intensity would increase by a factor $32$. Matrix-vector products would then have an arithmetic intensity of $16$ FLOPs/byte, which means they would be compute bound as well!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fbe315-44db-4b10-918b-74e37dd77bab",
   "metadata": {},
   "source": [
    "Question 3\n",
    "----------\n",
    "\n",
    "For this question we will be using numpy and [cupy](https://cupy.dev/)\n",
    "\n",
    "In this question we investigate the cost of data movement. To move data between CPUs in Python you would need to know MPI, which will be taught later on in the course. Here, we move data between CPUs and GPUs instead using cupy.\n",
    "\n",
    "* Read and understand the code below. Run it (possibly twice to make sure there is no caching). Do you expect matrix multiplications to be faster on the CPU or on the GPU? Do you expect it to be faster to move data to or from the GPU (or the same)?\n",
    "* Create a random square matrix $A$ and a vector $v$ of size $n=1024$ on the CPU (using numpy) and on the GPU (using cupy, it does not matter if the values are not the same). Then write three functions: 1) A function that computes $v\\cdot v$ on the CPU using the CPU variables. 2) A function that computes $v\\cdot v$ on the GPU using the GPU variables and then returns the answer to the CPU. 3) A function that copies $v$ onto the GPU, computes $v\\cdot v$ on the GPU, and then returns the answer to the CPU. Time all functions using 10 runs each. Remember to run it twice and to only take the second timing. Please add the lines\n",
    "```python\n",
    "mempool = cp.get_default_memory_pool()\n",
    "mempool.set_limit(size=1.5*1024**3)  # 1.5 GB limit on GPU memory usage.\n",
    "```\n",
    "before your code to make sure we do not overuse the GPU memory.\n",
    "\n",
    "* Repeat the above, but with $Av$.\n",
    "* Repeat the above, but with $A^2$.\n",
    "* Looking at the timings what do you observe? When is it worth it to move data to perform computations on the GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0f6838-325e-4458-8a18-14e371f3609a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time matmat CPU: 0.005548596382141113\n",
      "Time matmat GPU: 0.0057473421096801754\n",
      "Time CPU to GPU: 0.0025550127029418945\n",
      "Time GPU to CPU: 0.0008652210235595703\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from time import time\n",
    "\n",
    "mempool = cp.get_default_memory_pool()\n",
    "mempool.set_limit(size=1.5*1024**3)  # 1.5 GiB\n",
    "\n",
    "N = 1024\n",
    "\n",
    "x  = np.random.randn(N, N)\n",
    "xg = cp.random.randn(N, N)\n",
    "\n",
    "# Matrix multiplication on CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    x@x\n",
    "\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matmat CPU:\", t)\n",
    "\n",
    "# Matrix multiplication on GPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    xg@xg\n",
    "\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matmat GPU:\", t)\n",
    "\n",
    "# CPU to GPU data movement\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    yg = cp.asarray(x) # moves a numpy array stored on the CPU onto the GPU\n",
    "    \n",
    "t = (time()-tic)/10\n",
    "print(\"Time CPU to GPU:\", t)\n",
    "\n",
    "# GPU to CPU data movement.\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    y = cp.asnumpy(xg) # moves a cupy array stored on the GPU onto the CPU\n",
    "    \n",
    "t = (time()-tic)/10\n",
    "print(\"Time GPU to CPU:\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9a71d-4dec-4d56-8a88-3c5492c9e1bc",
   "metadata": {},
   "source": [
    "Solutions to question 3\n",
    "-----------------------\n",
    "\n",
    "GPU is supposed to be faster, but I haven't told you why yet. Data movement should in principle take the same time, but it seems like GPU to CPU is faster.\n",
    "\n",
    "The functions are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d73ff03-2b7f-4b30-bcd2-05f0335340a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time vdotv CPU: 9.894371032714844e-06\n",
      "Time vdotv GPU then move to CPU: 0.021835923194885254\n",
      "Time vdotv by moving to and from GPU: 0.0003664731979370117\n",
      "Time matvec CPU: 0.0008300542831420898\n",
      "Time matvec GPU then move to CPU: 0.000778818130493164\n",
      "Time matvec by moving to and from GPU: 0.001305699348449707\n",
      "Time matmat CPU: 0.0051013708114624025\n",
      "Time matmat GPU then move to CPU: 0.0037709712982177735\n",
      "Time matmat by moving to and from GPU: 0.00427541732788086\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "from time import time\n",
    "\n",
    "mempool = cp.get_default_memory_pool()\n",
    "mempool.set_limit(size=1.5*1024**3)  # 1.5 GiB\n",
    "\n",
    "N = 1024\n",
    "\n",
    "A  = np.random.randn(N, N)\n",
    "Ag = cp.random.randn(N, N)\n",
    "v  = np.random.randn(N)\n",
    "vg = cp.random.randn(N)\n",
    "\n",
    "# Note: these functions still work if you call them with A rather than v\n",
    "def vdot1(v):\n",
    "    return v@v\n",
    "\n",
    "def vdot2(vg):\n",
    "    outg = vg@vg\n",
    "    out = cp.asnumpy(outg)\n",
    "    return out\n",
    "\n",
    "def vdot3(v):\n",
    "    vgpu = cp.asarray(v)\n",
    "    outg = vgpu@vgpu\n",
    "    out = cp.asnumpy(outg)\n",
    "    return out\n",
    "\n",
    "def mat1(A,v):\n",
    "    return A@v\n",
    "\n",
    "def mat2(Ag,vg):\n",
    "    outg = Ag@vg\n",
    "    out = cp.asnumpy(outg)\n",
    "    return out\n",
    "\n",
    "def mat3(A,v):\n",
    "    Agpu = cp.asarray(A)\n",
    "    vgpu = cp.asarray(v)\n",
    "    outg = Agpu@vgpu\n",
    "    out = cp.asnumpy(outg)\n",
    "    return out\n",
    "\n",
    "\n",
    "######################## v \\cdot v ################################\n",
    "\n",
    "# vdotv on CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot1(v)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time vdotv CPU:\", t)\n",
    "\n",
    "# vdotv on GPU + move to CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot2(vg)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time vdotv GPU then move to CPU:\", t)\n",
    "\n",
    "# vdotv by moving to and from GPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot3(v)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time vdotv by moving to and from GPU:\", t)\n",
    "\n",
    "######################## Av ################################\n",
    "\n",
    "# Av on CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = mat1(A,v)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matvec CPU:\", t)\n",
    "\n",
    "# Av on GPU + move to CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = mat2(Ag,vg)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matvec GPU then move to CPU:\", t)\n",
    "\n",
    "# Av by moving to and from GPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = mat3(A,v)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matvec by moving to and from GPU:\", t)\n",
    "\n",
    "######################## A^2 ################################\n",
    "\n",
    "# A^2 on CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot1(A)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matmat CPU:\", t)\n",
    "\n",
    "# A^2 on GPU + move to CPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot2(Ag)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matmat GPU then move to CPU:\", t)\n",
    "\n",
    "# A^2 by moving to and from GPU\n",
    "tic = time()\n",
    "for i in range(10):\n",
    "    out = vdot3(A)\n",
    "t = (time()-tic)/10\n",
    "print(\"Time matmat by moving to and from GPU:\", t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b25675c-5729-43d3-b135-78ab75443a09",
   "metadata": {},
   "source": [
    "* $v \\cdot v$. Pure CPU solution is best.\n",
    "* $Av$. It pays off to use the GPU. Better if $A$ and $v$ are already there so that data movement is minimized. Why it pays off? $O(n^2)$ flops cost and $O(n)$ data movement.\n",
    "* $A^2$. It pays off to use the GPU. Better if $A$ is already there so that data movement is minimized. Why it pays off? $O(n^3)$ flops cost and $O(n^2)$ data movement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CuPy Kernel",
   "language": "python",
   "name": "cupy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
